{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"dataset/Set_A_02/gray/1005306.jpg\"\n",
    "json_path = \"dataset/anotations/via_project_15Apr2024_9h49m_json.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import json\n",
    "\n",
    "def load_json_data(json_path):\n",
    "    with open(json_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"画像をPIL形式で読み込み、OpenCV形式に変換して返す関数\"\"\"\n",
    "    try:\n",
    "        pil_image = Image.open(image_path)\n",
    "        open_cv_image = np.array(pil_image)\n",
    "        # 画像がグレースケールの場合、カラーに変換する\n",
    "        if len(open_cv_image.shape) == 2:\n",
    "            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            # Convert RGB to BGR\n",
    "            open_cv_image = open_cv_image[:, :, ::-1]\n",
    "        return open_cv_image\n",
    "    except IOError:\n",
    "        print(f\"Error loading image {image_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_rectangles(json_data):\n",
    "    \"\"\"JSONデータから'rect'形状の座標を抽出する関数\"\"\"\n",
    "    rectangles = []\n",
    "    for file_data in json_data.values():\n",
    "        for region in file_data[\"regions\"]:\n",
    "            shape_attributes = region[\"shape_attributes\"]\n",
    "            if shape_attributes[\"name\"] == \"rect\":\n",
    "                x = shape_attributes[\"x\"]\n",
    "                y = shape_attributes[\"y\"]\n",
    "                width = shape_attributes[\"width\"]\n",
    "                height = shape_attributes[\"height\"]\n",
    "                rectangles.append((x, y, width, height))\n",
    "    return rectangles\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"画像の前処理を行い、エッジ検出用の画像を返す関数\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(blurred, 50, 150)\n",
    "    return edged\n",
    "\n",
    "\n",
    "def find_contours(edged):\n",
    "    \"\"\"エッジから輪郭を検出し、近似する関数\"\"\"\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    shapes = []\n",
    "    for cnt in contours:\n",
    "        epsilon = 0.01 * cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 100:\n",
    "            shape_type = classify_shape(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            shapes.append((shape_type, x, y, w, h))\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def classify_shape(approx):\n",
    "    \"\"\"輪郭の頂点の数によって形状を分類する関数\"\"\"\n",
    "    num_vertices = len(approx)\n",
    "    if num_vertices == 4:\n",
    "        return \"rectangle\"\n",
    "    elif num_vertices > 4:\n",
    "        return \"ellipse\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def extract_text_from_regions(image, shapes):\n",
    "    \"\"\"指定された形状の領域からテキストを抽出する関数\"\"\"\n",
    "    texts = []\n",
    "    for shape, x, y, w, h in shapes:\n",
    "        roi = image[y : y + h, x : x + w]\n",
    "        text = pytesseract.image_to_string(roi, lang=\"jpn\", config=\"--psm 6\")\n",
    "        texts.append((shape, text))\n",
    "    return texts\n",
    "\n",
    "\n",
    "def detect_shapes_and_extract_text(image_path):\n",
    "    \"\"\"画像から形状を検出し、その形状の領域からテキストを抽出する一連の処理を行う関数\"\"\"\n",
    "    image = load_image(image_path)\n",
    "    if image is not None:\n",
    "        edged = preprocess_image(image)\n",
    "        shapes = find_contours(image)\n",
    "        extracted_texts = extract_text_from_regions(image, shapes)\n",
    "        return extracted_texts\n",
    "    return []\n",
    "\n",
    "\n",
    "def draw_rectangles(image, rectangles):\n",
    "    for x, y, width, height in rectangles:\n",
    "        cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = load_json_data(json_path)\n",
    "rectangles = extract_rectangles(json_data)\n",
    "image = load_image(image_path)\n",
    "image_with_rectangles = draw_rectangles(image, rectangles)\n",
    "cv2.imshow(\"Image with Bounding Boxes\", image_with_rectangles)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"画像をPIL形式で読み込み、OpenCV形式に変換して返す関数\"\"\"\n",
    "    try:\n",
    "        pil_image = Image.open(image_path)\n",
    "        open_cv_image = np.array(pil_image)\n",
    "        # 画像がグレースケールの場合、カラーに変換する\n",
    "        if len(open_cv_image.shape) == 2:\n",
    "            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            # Convert RGB to BGR\n",
    "            open_cv_image = open_cv_image[:, :, ::-1]\n",
    "        return open_cv_image\n",
    "    except IOError:\n",
    "        print(f\"Error loading image {image_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_contours(image):\n",
    "    \"\"\"画像から輪郭を検出し、多角形に近似する関数\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def approximate_polygons(contours, accuracy=0.02):\n",
    "    \"\"\"輪郭を多角形に近似し、その結果を返す関数\"\"\"\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        epsilon = accuracy * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        polygons.append(approx)\n",
    "    return polygons\n",
    "\n",
    "\n",
    "def draw_polygons(image, polygons):\n",
    "    \"\"\"多角形を画像に描画する関数\"\"\"\n",
    "    for polygon in polygons:\n",
    "        if len(polygon) >= 5:  # 5頂点以上の多角形を識別\n",
    "            cv2.polylines(image, [polygon], True, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Polygons Detected\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def extract_text_from_regions(image, shapes):\n",
    "    \"\"\"指定された形状の領域からテキストを抽出する関数\"\"\"\n",
    "    texts = []\n",
    "    for shape, x, y, w, h in shapes:\n",
    "        roi = image[y : y + h, x : x + w]\n",
    "        text = pytesseract.image_to_string(roi, lang=\"jpn\", config=\"--psm 6\")\n",
    "        texts.append((shape, text))\n",
    "    return texts\n",
    "\n",
    "\n",
    "def detect_shapes_and_extract_text(image_path):\n",
    "    \"\"\"画像から形状を検出し、その形状の領域からテキストを抽出する一連の処理を行う関数\"\"\"\n",
    "    image = load_image(image_path)\n",
    "    if image is not None:\n",
    "        shapes = find_contours(image)\n",
    "        extracted_texts = extract_text_from_regions(image, shapes)\n",
    "        return extracted_texts\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_shapes(image_path):\n",
    "    # 画像を読み込み、グレースケールに変換\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # エッジ検出\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "    # 輪郭を見つける\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    shapes = []\n",
    "    for cnt in contours:\n",
    "        # 輪郭の近似\n",
    "        epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "        # 四角形を検出（例: バスタブや洗面台）\n",
    "        if len(approx) == 4:\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            shapes.append((\"rectangle\", x, y, w, h))\n",
    "\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"画像を読み込む関数\"\"\"\n",
    "    return Image.open(image_path)\n",
    "\n",
    "\n",
    "def extract_text_from_coordinates(image_path, coordinates):\n",
    "    \"\"\"指定された座標のバウンディングボックスからテキストを抽出する関数\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    texts = []\n",
    "\n",
    "    for coord in coordinates:\n",
    "        x, y, w, h = coord[1], coord[2], coord[3], coord[4]\n",
    "        # バウンディングボックスに基づいて部分画像を切り出す\n",
    "        roi = image[y : y + h, x : x + w]\n",
    "        # ROIからテキストを抽出\n",
    "        text = pytesseract.image_to_string(roi, lang=\"jpn\", config=\"--psm 6\")\n",
    "        texts.append((coord, text))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_labels = [\"リビング\", \"キッチン\", \"浴室\", \"トイレ\", \"寝室\", \"玄関\", \"洗面所\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: ellipse, Extracted Text: | |\n",
      "\f\n",
      "Shape: ellipse, Extracted Text: \f\n",
      "Shape: ellipse, Extracted Text: \f\n",
      "Shape: ellipse, Extracted Text: 浴\n",
      "\f\n",
      "Shape: ellipse, Extracted Text: 玄関\n",
      "\f\n",
      "Shape: ellipse, Extracted Text:   浴室\n",
      "\n",
      "ゴゴッ*\n",
      "\n",
      "_ 還E\n",
      "\n",
      "|     洋室      に\n",
      "ロ\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = detect_shapes_and_extract_text(image_path)\n",
    "for result in results:\n",
    "    print(f\"Shape: {result[0]}, Extracted Text: {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import numpy as np\n",
    "\n",
    "def extract_text(image):\n",
    "    \"\"\"OCRを使用して画像からテキストとその座標を抽出する関数\"\"\"\n",
    "    custom_config = r\"--oem 1 --psm 11 -l jpn\"\n",
    "    data = pytesseract.image_to_data(\n",
    "        image, config=custom_config, output_type=Output.DICT\n",
    "    )\n",
    "\n",
    "    text_info = []\n",
    "    num_items = len(data[\"text\"])\n",
    "    for i in range(num_items):\n",
    "        if int(data[\"conf\"][i]) > 30:\n",
    "            x, y, w, h = (\n",
    "                data[\"left\"][i],\n",
    "                data[\"top\"][i],\n",
    "                data[\"width\"][i],\n",
    "                data[\"height\"][i],\n",
    "            )\n",
    "            text = data[\"text\"][i]\n",
    "            text_info.append((text, (x, y, w, h)))\n",
    "    return text_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def find_best_match(text, labels):\n",
    "    best_match = process.extractOne(text, labels)\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def group_text_blocks(text_info, max_distance=10):\n",
    "    grouped_text = []\n",
    "    if not text_info:\n",
    "        return grouped_text\n",
    "\n",
    "    # 最初のテキストブロックを初期グループとして設定\n",
    "    current_group = [text_info[0]]\n",
    "\n",
    "    for current_text, (x, y, w, h) in text_info[1:]:\n",
    "        last_text, (last_x, last_y, last_w, last_h) = current_group[-1]\n",
    "        # 次のテキストブロックとの距離を計算\n",
    "        if (x <= (last_x + last_w + max_distance)) and (\n",
    "            y <= (last_y + last_h + max_distance)\n",
    "        ):\n",
    "            # 座標が近い場合、グループに追加\n",
    "            current_group.append((current_text, (x, y, w, h)))\n",
    "        else:\n",
    "            # 遠い場合、現在のグループをまとめて新たにグループ化を開始\n",
    "            grouped_text.append(\" \".join([text for text, _ in current_group]))\n",
    "            current_group = [(current_text, (x, y, w, h))]\n",
    "\n",
    "    # 最後のグループを追加\n",
    "    grouped_text.append(\" \".join([text for text, _ in current_group]))\n",
    "    return grouped_text\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = load_image(image_path)\n",
    "    text_info = extract_text(image)\n",
    "    grouped_texts = group_text_blocks(text_info)\n",
    "    return grouped_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "玄関\n",
      "バ ル\n",
      "同 洋室\n"
     ]
    }
   ],
   "source": [
    "resulting_texts = process_image(image_path)\n",
    "for text in resulting_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
