{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"床面\", \"椅子\", \"収納\", \"玄関\", \"浴槽\", \"洗面台\"]\n",
    "\n",
    "class_labels = { i: class_name for i, class_name in enumerate(class_names)}\n",
    "class_ids = [i for i in range(len(class_names))]\n",
    "\n",
    "\n",
    "def get_class_key(class_name):\n",
    "    return class_names.index(class_name)\n",
    "\n",
    "def get_class_name(class_key):\n",
    "    return class_names[class_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_dir = \"dataset/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 08:50:25.897064: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-02 08:50:25.934941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 08:50:26.494857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/onikarubi/documents/team-shiny-products/floor-plan-ocr/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from keras_cv import bounding_box\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_annotation(annotation_file):\n",
    "    annotations = []\n",
    "\n",
    "    with open(annotation_file) as f:\n",
    "        annotation_dict = json.load(f)\n",
    "\n",
    "    for k, data in annotation_dict.items():\n",
    "        file_name = data[\"filename\"]\n",
    "        size = data[\"size\"]\n",
    "        regions = data[\"regions\"]\n",
    "        bounding_boxes = []\n",
    "\n",
    "        for region in regions:\n",
    "            bbox = convert_bbox_to_kerascv_format(region)\n",
    "\n",
    "            if bbox is None:\n",
    "                continue\n",
    "\n",
    "            bounding_boxes.append(bbox)\n",
    "\n",
    "        annotations.append({\n",
    "            \"file_name\": file_name,\n",
    "            \"size\": size,\n",
    "            \"bounding_boxes\": bounding_boxes\n",
    "        })\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def convert_bbox_to_kerascv_format(region):\n",
    "    shape_attributes = region['shape_attributes']\n",
    "    region_attributes = region['region_attributes']\n",
    "\n",
    "    shape_name = shape_attributes['name']\n",
    "\n",
    "    if shape_name != 'rect':\n",
    "        print('shape name is not rect', shape_name)\n",
    "        return None\n",
    "\n",
    "    x = shape_attributes['x']\n",
    "    y = shape_attributes['y']\n",
    "    width = shape_attributes['width']\n",
    "    height = shape_attributes['height']\n",
    "    class_name = region_attributes['class']\n",
    "\n",
    "    boxes = {\n",
    "        'classes': get_class_key(class_name),\n",
    "        \"boxes\": np.array([x, y, x + width, y + height])\n",
    "    }\n",
    "    bbox = bounding_box.convert_format(boxes, 'xywh', 'xywh')\n",
    "\n",
    "    return bbox\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (512, 512))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape name is not rect polyline\n",
      "shape name is not rect polyline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 08:50:31.152381: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-02 08:50:31.158467: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file_name': '1005310.jpg',\n",
       "  'size': 11046,\n",
       "  'bounding_boxes': [{'classes': 0,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 14., 243., 104., 267.], dtype=float32)>},\n",
       "   {'classes': 2,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 15.,  91.,  55., 117.], dtype=float32)>},\n",
       "   {'classes': 3,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([60., 29., 94., 40.], dtype=float32)>},\n",
       "   {'classes': 2,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([43., 29., 59., 42.], dtype=float32)>},\n",
       "   {'classes': 4,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([14., 44., 55., 86.], dtype=float32)>},\n",
       "   {'classes': 0,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([16., 29., 44., 42.], dtype=float32)>},\n",
       "   {'classes': 5,\n",
       "    'boxes': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 86.,  47., 101.,  63.], dtype=float32)>}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_dict = load_annotation(\n",
    "    annotation_file=annotation_dir + \"via_project_15Apr2024_9h49m_json.json\"\n",
    ")\n",
    "\n",
    "annotation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = {\n",
    "    \"shape_attributes\": {\"name\": \"rect\", \"x\": 15, \"y\": 91, \"width\": 40, \"height\": 26},\n",
    "    \"region_attributes\": {\n",
    "        \"floor_label\": \"収納\",\n",
    "        \"class\": \"収納\",\n",
    "        \"description\": \"収納スペース\",\n",
    "    },\n",
    "}\n",
    "\n",
    "bbox = convert_bbox_to_kerascv_format(region)\n",
    "print(\"Converted BoundingBox:\", bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def draw_bbox(image_path, bbox, color='red', width=3):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    boxes = bbox['boxes']\n",
    "    classes = bbox['classes']\n",
    "\n",
    "    draw.rectangle(boxes, outline=color, width=width)\n",
    "\n",
    "    label_position = (boxes[0], boxes[1] - 18)\n",
    "    draw.text(label_position, get_class_name(classes), fill=color)\n",
    "    image.show()\n",
    "\n",
    "img_path = \"dataset/Set_A_02/color/1005310.jpg\"\n",
    "draw_bbox(img_path, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
